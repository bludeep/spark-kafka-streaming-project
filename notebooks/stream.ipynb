{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d8076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "def spark_init():\n",
    "    spark = ( SparkSession.builder.appName(\"KafkaStreamReader\")\n",
    "        .master(\"local[2]\")  \n",
    "        .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.6.0\")\")\n",
    "        .config(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\")\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "        .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "        .config(\"spark.executor.memory\", \"4g\")\n",
    "        .config(\"spark.driver.memory\", \"4g\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"2\")\n",
    "        .getOrCreate()\n",
    "        )\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    return spark \n",
    "\n",
    "\n",
    "\n",
    "def read_stream(spark, topic):\n",
    "    df = ( spark.readStream\n",
    "        .format(\"kafka\")\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:9092\")\n",
    "        .option(\"subscribe\", topic)\n",
    "        .option(\"startingOffsets\", \"earliest\")\n",
    "        .load() \n",
    "                )\n",
    "    return df.select(\n",
    "        col(\"key\").cast(\"string\")\n",
    "        ,col(\"value\").cast(\"string\")\n",
    "        ,\"topic\"\n",
    "        ,\"partition\"\n",
    "        ,\"timestamp\"\n",
    "        ,\"offset\"\n",
    "    )\n",
    "\n",
    "def kafka_value_parsed(df):\n",
    "    schema = StructType([\n",
    "    StructField(\"Price\", DoubleType(), True),\n",
    "    StructField(\"District\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Town\", StringType(), True),\n",
    "    StructField(\"Type\", StringType(), True),\n",
    "    StructField(\"EnergyCertificate\", StringType(), True),\n",
    "    StructField(\"GrossArea\", DoubleType(), True),\n",
    "    StructField(\"TotalArea\", DoubleType(), True),\n",
    "    StructField(\"Parking\", DoubleType(), True),\n",
    "    StructField(\"HasParking\", BooleanType(), True),\n",
    "    StructField(\"Floor\", StringType(), True),\n",
    "    StructField(\"ConstructionYear\", DoubleType(), True),\n",
    "    StructField(\"EnergyEfficiencyLevel\", StringType(), True),\n",
    "    StructField(\"PublishDate\", TimestampType(), True),\n",
    "    StructField(\"Garage\", BooleanType(), True),\n",
    "    StructField(\"Elevator\", BooleanType(), True),\n",
    "    StructField(\"ElectricCarsCharging\", BooleanType(), True),\n",
    "    StructField(\"TotalRooms\", DoubleType(), True),\n",
    "    StructField(\"NumberOfBedrooms\", DoubleType(), True),\n",
    "    StructField(\"NumberOfWC\", DoubleType(), True),\n",
    "    StructField(\"ConservationStatus\", StringType(), True),\n",
    "    StructField(\"LivingArea\", DoubleType(), True),\n",
    "    StructField(\"LotSize\", DoubleType(), True),\n",
    "    StructField(\"BuiltArea\", DoubleType(), True),\n",
    "    StructField(\"NumberOfBathrooms\", DoubleType(), True)\n",
    "])\n",
    "    df = df.select(\n",
    "        \"key\"\n",
    "        ,from_json(col(\"value\"), schema).alias(\"parsed_data\")\n",
    "        ,col(\"timestamp\").alias(\"kafka_timestamp\")\n",
    "        ,\"topic\"\n",
    "        ,\"partition\"\n",
    "        ,\"offset\"\n",
    "    )\n",
    "    return df.select(\n",
    "        \"key\"\n",
    "        ,\"parsed_data.*\"\n",
    "        ,\"kafka_timestamp\"\n",
    "        ,\"offset\"\n",
    "        ,\"partition\"\n",
    "    )\n",
    "\n",
    "def clean_and_filter_kafka(df):\n",
    "    df = df.replace(['nan', 'NaN', 'null', ''], None)\n",
    "\n",
    "    df = df.withColumn(\"price\", \n",
    "        when(isnan(col(\"price\")) | isnull(col(\"price\")), None).otherwise(col(\"price\")))\n",
    "    \n",
    "    df = df.withColumn(\"main_area\",\n",
    "        when(col(\"type\") == \"Land\", \n",
    "             coalesce(col(\"lotsize\"), col(\"totalarea\"), col(\"grossarea\")))\n",
    "        .when(col(\"type\") == \"Farm\", \n",
    "             coalesce(col(\"lotsize\"), col(\"totalarea\"), col(\"grossarea\")))\n",
    "        .when(col(\"type\").isin([\"Apartment\", \"Studio\", \"Duplex\"]), \n",
    "             coalesce(col(\"livingarea\"), col(\"totalarea\"), col(\"grossarea\")))\n",
    "        .when(col(\"type\").isin([\"House\", \"Mansion\", \"Manor\", \"Estate\"]), \n",
    "             coalesce(col(\"livingarea\"), col(\"builtarea\"), col(\"totalarea\"), col(\"grossarea\")))\n",
    "        .when(col(\"type\").isin([\"Office\", \"Store\", \"Warehouse\", \"Industrial\", \"Storage\", \"Hotel\"]), \n",
    "             coalesce(col(\"totalarea\"), col(\"grossarea\"), col(\"builtarea\")))\n",
    "        .when(col(\"type\") == \"Garage\", \n",
    "             coalesce(col(\"builtarea\"), col(\"totalarea\"), col(\"grossarea\")))\n",
    "        .when(col(\"type\") == \"Building\", \n",
    "             coalesce(col(\"totalarea\"), col(\"grossarea\"), col(\"builtarea\")))\n",
    "        .otherwise(coalesce(col(\"totalarea\"), col(\"grossarea\"), col(\"livingarea\")))\n",
    "    ).filter(\n",
    "        col(\"price\").isNotNull() & \n",
    "        (col(\"price\") > 50000) &\n",
    "        col(\"main_area\").isNotNull() & \n",
    "        ~isnan(col(\"main_area\")) &\n",
    "        (col(\"main_area\") > 20) &\n",
    "        col(\"district\").isNotNull() &\n",
    "        col(\"type\").isNotNull()\n",
    "    )\n",
    "    \n",
    "    return df.select(col(\"type\").alias(\"property_type\"), \"district\", \"price\", \"main_area\")\n",
    "\n",
    "def calculate_aggregations(df):\n",
    "    aggregate_df = df.groupBy([\"property_type\", \"district\"]) \\\n",
    "                .agg(\n",
    "                    round(avg(\"price\"), 2).alias(\"avg_price\")\n",
    "                    ,round(avg(\"main_area\"), 2).alias(\"avg_area\")\n",
    "                    ,count(\"*\").alias(\"total_ads\")\n",
    "                    ,round((sum(\"price\") / sum(\"main_area\")), 2).alias(\"avg_price_per_sqm\")\n",
    "                ).orderBy([\"district\", \"property_type\"])\n",
    "    return aggregate_df\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "topic = \"csv-data\"\n",
    "spark = spark_init()\n",
    "stream = read_stream(spark, topic)\n",
    "parsed_df = kafka_value_parsed(stream)\n",
    "cleaned_kafka = clean_and_filter_kafka(parsed_df)\n",
    "aggregations = calculate_aggregations(cleaned_kafka)\n",
    "\n",
    "query = ( aggregations.writeStream\n",
    "         .outputMode(\"complete\")\n",
    "         .format(\"console\")\n",
    "         .trigger(processingTime=\"30 seconds\")\n",
    "         .start()\n",
    ")\n",
    "\n",
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
