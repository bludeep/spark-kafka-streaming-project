{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d8076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = ( SparkSession.builder.appName(\"KafkaStreamReader\")\n",
    "        .master(\"local[2]\")  \n",
    "        .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\")\n",
    "        .config(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\")\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "        .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "        .config(\"spark.executor.memory\", \"4g\")\n",
    "        .config(\"spark.driver.memory\", \"4g\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"2\")\n",
    "        .getOrCreate()\n",
    "        )\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "\n",
    "sample_json = spark.read \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"csv-data\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"endingOffsets\", \"latest\") \\\n",
    "    .load() \\\n",
    "    .select(col(\"value\").cast(\"string\")) \\\n",
    "    .first().value\n",
    "\n",
    "auto_schema = spark.range(1).select(schema_of_json(lit(sample_json)).alias(\"schema\")).collect()[0].schema\n",
    "\n",
    "df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"csv-data\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load() \n",
    "\n",
    "parsed_df = df.select(\n",
    "    col(\"key\").cast(\"string\")\n",
    "    ,from_json(col(\"value\").cast(\"string\"), auto_schema).alias(\"parsed_value\")\n",
    "    ,col(\"timestamp\").alias(\"kafka_timestamp\")\n",
    "    ,col(\"partition\")\n",
    "    ,col(\"offset\")\n",
    ").select(\n",
    "    \"key\"\n",
    "    ,\"parsed_value.*\"\n",
    "    ,\"kafka_timestamp\"\n",
    "    ,\"offset\"\n",
    "    ,\"partition\"\n",
    ")\n",
    "\n",
    "df_with_area = parsed_df.withColumn(\n",
    "    \"area_for_price\",\n",
    "    when(col(\"Type\") == \"Garage\", col(\"TotalArea\"))\n",
    "    .when(col(\"Type\") == \"Land\", col(\"LotSize\"))\n",
    "    .when(col(\"Type\").isin(\"Office\", \"Building\", \"Hotel\"), col(\"GrossArea\"))\n",
    "    .otherwise(col(\"LivingArea\"))\n",
    ")\n",
    "\n",
    "filtered_df = ( df_with_area\n",
    "        .filter((col(\"Price\") >= 50_000) &\n",
    "        (col(\"area_for_price\") >= 20) &\n",
    "        col(\"Price\").isNotNull() &\n",
    "        col(\"LivingArea\").isNotNull()\n",
    "))\n",
    "\n",
    "grouped_df = ( filtered_df\n",
    "            .groupBy([\"type\", \"district\"])\n",
    "            .agg(\n",
    "                avg(\"Price\").alias(\"avg_price\")\n",
    "                ,avg(\"area_for_price\").alias(\"avg_area\")\n",
    "                ,count(\"*\").alias(\"total_ads\")\n",
    "                ,avg(col(\"price\") / col(\"area_for_price\")).alias(\"avg_price_for_sqt\")\n",
    "                )\n",
    "            .orderBy([\"district\", \"type\"])\n",
    "             )\n",
    "\n",
    "query = ( grouped_df.writeStream\n",
    "         .outputMode(\"complete\")\n",
    "         .format(\"console\")\n",
    "         .trigger(processingTime='30 seconds')\n",
    "         .start()\n",
    ")\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
